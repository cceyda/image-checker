{
 "cells": [
  {
   "source": [
    "# Jpeg Decoding Benchmark\n",
    "The purpose of this notebook isn't to come to a conclusion about which library is faster. Since little setup differences in versions can make differences and notebooks themselves are not a contained environment. aka **your milage may vary**.\n",
    "\n",
    "The purpose is to have a simple notebook you can run on your setup to see what is what. Help you see if you can make some improvements. For example; Updating turbojpeg to 2.1 version if you are doing CPU decoding, or trying out GPU decoding etc etc (in my experience, Nvidia DALI gpu decoding is always faster)\n",
    "\n",
    "Let me know if you spot mistakes & or share your results in a gist."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from image_checker.checker import batch\n",
    "from image_checker.DaliChecker import DaliChecker\n",
    "from image_checker.iterators import folder_iterator\n",
    "from PIL import Image\n",
    "from torchvision import transforms as t\n",
    "from torchvision.io import decode_image,decode_jpeg, read_image\n",
    "from torchvision import __version__ as torchvision_version\n",
    "from more_itertools import chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -c \"import fastai.utils; fastai.utils.check_perf()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Bytes->Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_count=256\n",
    "folder=\"/home1/ceyda/data/dali_test/fine/\" # a folder full of jpegs\n",
    "files=folder_iterator(folder,extensions=[\"jpg\",\"jpeg\"],recursive=False)\n",
    "images_bytes=[im for im,path in files][:img_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing this here so it doesn't effect time\n",
    "images_bytes_io=[io.BytesIO(i) for i in images_bytes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIL-SIMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from PIL.features import check_feature\n",
    "check_feature(\"libjpeg_turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ceyda/.local/lib/python3.6/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  img = torch.as_tensor(np.asarray(pic))\n",
      "692 ms ± 15.1 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "# PIL_SIMD -> Tensor output\n",
    "for image_bytes in images_bytes_io:\n",
    "    z=Image.open(image_bytes)\n",
    "    z=t.functional.pil_to_tensor(z)\n",
    "#     z.to(\"cuda:0\")\n",
    "# Tensor output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torchvision_version 0.10.0+cu102\nTrue\n10.2\n10020 cuda compiled version\n"
     ]
    }
   ],
   "source": [
    "assert '0.10' in torchvision_version\n",
    "print('torchvision_version',torchvision_version)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch._C._cuda_getCompiledVersion(), 'cuda compiled version')\n",
    "# CUDA version >= 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "514 ms ± 20.9 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "for img_bytes in images_bytes:\n",
    "    z=torch.from_numpy(img_bytes)\n",
    "#     z=z.to(\"cuda:0\")\n",
    "    z=decode_jpeg(z)\n",
    "# z=z.to(\"cuda:0\")\n",
    "# Tensor output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision (GPU) (BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "913 ms ± 81.2 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "for img_bytes in images_bytes:\n",
    "    z=torch.from_numpy(img_bytes)\n",
    "#     z=z.to(\"cuda:0\")\n",
    "    z=decode_jpeg(z, device='cuda')\n",
    "    # torch.cuda.synchronize()\n",
    "#     z.to(\"cuda:0\")\n",
    "# Tensor output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n",
    "# !python3 collect_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvidia DALI (nvJPEG on GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256 #speed can change depending on batch size\n",
    "dali_decoder = DaliChecker(batch_size, prefetch=1, device='mixed') # mixed means GPU+CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_of_image_bytes=list(chunked(images_bytes,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "195 ms ± 13.2 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "for image_bytes in batches_of_image_bytes:\n",
    "    dali_decoder.feed(image_bytes)\n",
    "    dali_tensor=dali_decoder.pipe.run()\n",
    "    # dali_tensor is on the GPU!\n",
    "    # Tensor output even moved to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvidia DALI (on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "dali_decoder = DaliChecker(batch_size, prefetch=1, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_of_image_bytes=list(chunked(images_bytes,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "487 ms ± 27.6 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "for image_bytes in batches_of_image_bytes:\n",
    "    dali_decoder.feed(image_bytes)\n",
    "    dali_tensor=dali_decoder.pipe.run()\n",
    "    # dali_tensor is on the CPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "libjpeg-turbo (ver 2.0.6-62)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "cv2_jpeg_lib = re.search(\n",
    "    r\".*JPEG:\\W+(?P<jpeg_lib>.*)\", cv.getBuildInformation()\n",
    ").groupdict()[\"jpeg_lib\"]\n",
    "print(cv2_jpeg_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "880 ms ± 20.6 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "for img_bytes in images_bytes:\n",
    "    z = cv.imdecode(img_bytes, cv.IMREAD_COLOR)\n",
    "    # z is decoded image\n",
    "    z=torch.as_tensor(z)\n",
    "#     print(z)\n",
    "    # z is Tensor on cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleJpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install simplejpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "442 ms ± 16.9 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "# simplejpeg\n",
    "for img_bytes in images_bytes:\n",
    "    z=simplejpeg.decode_jpeg(img_bytes, fastdct=True, fastupsample=True)\n",
    "    # z is decoded image\n",
    "    z=torch.as_tensor(z)\n",
    "    # z is Tensor on cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTurboJPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install PyTurboJPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turbojpeg import TurboJPEG,TJFLAG_FASTUPSAMPLE,TJFLAG_FASTDCT\n",
    "# specifying library path explicitly\n",
    "# jpeg = TurboJPEG('/usr/lib64/libturbojpeg.so')\n",
    "# using default library installation\n",
    "jpeg = TurboJPEG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "497 ms ± 16.7 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 100\n",
    "for img_bytes in images_bytes:\n",
    "    # z = jpeg.decode(img_bytes)\n",
    "    z = jpeg.decode(img_bytes,flags=TJFLAG_FASTUPSAMPLE|TJFLAG_FASTDCT) # with flags around -50ms faster\n",
    "    # z is decoded image\n",
    "    z = torch.as_tensor(z)\n",
    "    # z is Tensor on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on TITAN RTX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}